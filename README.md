# ğŸ“„ PDF-based Retrieval-Augmented Generation (RAG)

This project implements a **Retrieval-Augmented Generation (RAG)** pipeline for answering questions based on **scanned PDF documents** using OCR, dense embeddings, and a local Large Language Model (LLM).

The system is designed to run efficiently on **Kaggle** and follows best practices for scalable and explainable RAG systems.

---

## ğŸš€ Features

- OCR for scanned PDF documents using **Tesseract**
- Text cleaning and chunking optimized for OCR output
- Semantic embedding using **BAAI/bge-m3**
- Fast vector search with **FAISS**
- Retrieval-Augmented prompt injection
- Question Answering with **Sahabat AI v1 8B Instruct**
- Persistent FAISS index (no re-embedding needed)

---

## ğŸ§  RAG Architecture

PDF (Scanned)
â†“
OCR (Tesseract)
â†“
Text Cleaning
â†“
Chunking
â†“
Embedding (bge-m3)
â†“
FAISS Vector Index
â†“
Retriever (Top-K)
â†“
Augmented Prompt
â†“
LLM (Sahabat AI)
â†“
Answer


---

## ğŸ› ï¸ Tech Stack

| Component | Technology |
|---------|-----------|
| OCR | Tesseract OCR |
| Embedding | BAAI/bge-m3 |
| Vector Database | FAISS |
| LLM | Sahabat AI v1 8B Instruct |
| Frameworks | Sentence-Transformers, HuggingFace Transformers |
| Environment | Kaggle Notebook (GPU P100 recommended) |

---

## ğŸ“¦ Installation

```bash
pip install sentence-transformers transformers accelerate faiss-cpu pytesseract pillow
apt-get install tesseract-ocr tesseract-ocr-ind

.
â”œâ”€â”€ chunks.pkl
â”œâ”€â”€ data.pdf
â”œâ”€â”€ index.faiss
â”œâ”€â”€ notebook.ipynb
â””â”€â”€ README.md

import faiss
index = faiss.read_index("faiss_store/index.faiss")
```
